{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing data for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_df            = pd.read_csv ('data/preprocessed_data/g_df.csv')\n",
    "t_df            = pd.read_csv ('data/preprocessed_data/t_df.csv')\n",
    "G_T_df          = pd.read_csv ('data/preprocessed_data/G_T_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82552, 3)\n",
      "(136, 464)\n",
      "(607, 55)\n"
     ]
    }
   ],
   "source": [
    "print (G_T_df.shape)\n",
    "print (g_df.shape)\n",
    "print (t_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Splitting for training, cross validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_T_train, G_T_test  = train_test_split (G_T_df, test_size = 0.1, random_state = rand_state  )\n",
    "G_T_train, G_T_cv    = train_test_split (G_T_train, test_size = 0.1, random_state = rand_state  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66866, 3)\n",
      "(7430, 3)\n",
      "(8256, 3)\n"
     ]
    }
   ],
   "source": [
    "print (G_T_train.shape)\n",
    "print (G_T_cv.shape)\n",
    "print (G_T_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-Resampling training set\n",
    "- resample training set so that the number of 1's equals to the number of 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0.0    64393\n",
       "1.0     2473\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_T_train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = G_T_train[G_T_train['target'] == 0]\n",
    "minority_class = G_T_train[G_T_train['target'] == 1]\n",
    "\n",
    "num_instances_to_replicate = len(majority_class) - len(minority_class)\n",
    "\n",
    "replicated_instances = resample(minority_class, n_samples=num_instances_to_replicate, random_state=42)\n",
    "\n",
    "# Concatenate the replicated instances with the original minority class\n",
    "balanced_G_T_train = pd.concat([majority_class, minority_class, replicated_instances])\n",
    "\n",
    "# shuffling train set\n",
    "balanced_G_T_train = balanced_G_T_train.sample(frac = 1, random_state= rand_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1.0    64393\n",
       "0.0    64393\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_G_T_train['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 128786 entries, 54731 to 69520\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   group ID      128786 non-null  object \n",
      " 1   technique ID  128786 non-null  object \n",
      " 2   target        128786 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "balanced_G_T_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Constructing Group, Technique, and Target matrices for Training, Cross Validation and Test set\n",
    "- Constructing one-hot encoded Group and Technique datasets so that they match the dimensions of target datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 464)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = pd.merge (g_df, balanced_G_T_train, on = 'group ID', how = 'right')\n",
    "G_train.drop (columns= ['technique ID', 'target'], inplace = True)\n",
    "\n",
    "T_train = pd.merge (t_df,balanced_G_T_train, on = 'technique ID', how = 'right')\n",
    "T_train.drop (columns= ['group ID', 'target'], inplace= True)\n",
    "\n",
    "G_cv = pd.merge (g_df, G_T_cv, on = 'group ID', how = 'right') \n",
    "G_cv.drop (columns= ['technique ID', 'target'], inplace = True)\n",
    "\n",
    "T_cv = pd.merge (t_df, G_T_cv, on = 'technique ID', how = 'right')\n",
    "T_cv.drop (columns= ['group ID', 'target'], inplace= True)\n",
    "\n",
    "G_test = pd.merge (g_df, G_T_test, on = 'group ID', how = 'right') \n",
    "G_test.drop (columns= ['technique ID', 'target'], inplace = True)\n",
    "\n",
    "T_test = pd.merge (t_df, G_T_test, on = 'technique ID', how = 'right')\n",
    "T_test.drop (columns= ['group ID', 'target'], inplace= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset dimensions\n",
      "(128786, 464)\n",
      "(128786, 55)\n",
      "(128786, 3)\n",
      "cross validation dataset dimensions\n",
      "(7430, 464)\n",
      "(7430, 55)\n",
      "(7430, 3)\n",
      "test dataset dimensions\n",
      "(8256, 464)\n",
      "(8256, 55)\n",
      "(8256, 3)\n"
     ]
    }
   ],
   "source": [
    "print (\"train dataset dimensions\")\n",
    "print (G_train.shape)\n",
    "print (T_train.shape)\n",
    "print (balanced_G_T_train.shape)\n",
    "\n",
    "print (\"cross validation dataset dimensions\")\n",
    "print (G_cv.shape)\n",
    "print (T_cv.shape)\n",
    "print (G_T_cv.shape)\n",
    "\n",
    "print (\"test dataset dimensions\")\n",
    "print (G_test.shape)\n",
    "print (T_test.shape)\n",
    "print (G_T_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "\"G_train\" : G_train,\n",
    "\"T_train\" : T_train,\n",
    "\"balanced_G_T_train\" : balanced_G_T_train,\n",
    "\"G_cv\" : G_cv,\n",
    "\"T_cv\" : T_cv,\n",
    "\"G_T_cv\" : G_T_cv,\n",
    "\"G_test\" : G_test,\n",
    "\"T_test\" : T_test,\n",
    "\"G_T_test\" : G_T_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attck_utils\n",
    "for key in dfs.keys():\n",
    "    # dfs[key].to_csv (f\"preprocessed_data/{key}.csv\", index = False)\n",
    "    attck_utils.save_df_to_csv (\n",
    "    path = 'data/preprocessed_data',\n",
    "    filename = key,\n",
    "    df = dfs[key]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfNote01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
