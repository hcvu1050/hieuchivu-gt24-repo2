{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note for model v0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/models') \n",
    "sys.path.append('../src/data') \n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model1.dataloader import load_data\n",
    "from model1.model_v0_4 import ContentBasedFiltering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\t train_dataset\n",
      "loaded:\t train_dataset\n",
      "loading\t cv_dataset\n",
      "loaded:\t cv_dataset\n",
      "loading\t test_dataset\n",
      "loaded:\t test_dataset\n",
      "train_dataset: 5549 examples\n",
      "cv_dataset: 12140 examples\n",
      "test_dataset: 12747 examples\n"
     ]
    }
   ],
   "source": [
    "train_dataset, cv_dataset, test_dataset, info = load_data(sample_train= 0.05, feature_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(train_dataset))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_dataset = cv_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_G_features = info['X_group_num_features']\n",
    "num_T_features = info['X_technique_num_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 463)\n",
      "(None, 54)\n"
     ]
    }
   ],
   "source": [
    "model1 = ContentBasedFiltering (\n",
    "    num_G_features=num_G_features, \n",
    "    num_T_features=num_T_features,\n",
    "    Group_NN_width = 16,\n",
    "    Group_NN_depth = 3,\n",
    "    Technique_NN_width = 16,\n",
    "    Technique_NN_depth = 3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"content_based_filtering\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Group_NN (Sequential)       (None, 32)                8512      \n",
      "                                                                 \n",
      " Technique_NN (Sequential)   (None, 32)                1968      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,480\n",
      "Trainable params: 10,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Group_NN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 16)                7424      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " output_Group (Dense)        (None, 32)                544       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,512\n",
      "Trainable params: 8,512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"Technique_NN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 16)                880       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " output_Tecnique (Dense)     (None, 32)                544       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,968\n",
      "Trainable params: 1,968\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.Group_NN.summary()\n",
    "model1.Technique_NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model1\u001b[39m.\u001b[39mfit (\n\u001b[0;32m      3\u001b[0m     train_dataset,\n\u001b[0;32m      4\u001b[0m     validation_data \u001b[39m=\u001b[39m cv_dataset,\n\u001b[0;32m      5\u001b[0m     epochs\u001b[39m=\u001b[39m epochs\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\engine\\training.py:3685\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assert_compile_was_called\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   3680\u001b[0m     \u001b[39m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[0;32m   3681\u001b[0m     \u001b[39m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[0;32m   3682\u001b[0m     \u001b[39m# model is compiled\u001b[39;00m\n\u001b[0;32m   3683\u001b[0m     \u001b[39m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[0;32m   3684\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_compiled:\n\u001b[1;32m-> 3685\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m   3686\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must compile your model before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3687\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtraining/testing. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3688\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   3689\u001b[0m         )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "history = model1.fit (\n",
    "    train_dataset,\n",
    "    validation_data = cv_dataset,\n",
    "    epochs= epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test_dataset \u001b[39m=\u001b[39m test_dataset\u001b[39m.\u001b[39mbatch(batch_size)\n\u001b[1;32m----> 3\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model1\u001b[39m.\u001b[39mevaluate (test_dataset)\n",
      "File \u001b[1;32mc:\\Users\\vuchi\\GT24\\hieuchivu-gt24-repo2\\notebooks\\../src/models\\model1\\model_v0_3.py:96\u001b[0m, in \u001b[0;36mContentBasedFiltering.evaluate\u001b[1;34m(self, test_dataset)\u001b[0m\n\u001b[0;32m     92\u001b[0m total_samples \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[39mfor\u001b[39;00m x_batch, y_batch \u001b[39min\u001b[39;00m test_dataset:\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Compute predictions and loss for each batch\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     batch_loss, batch_accuracy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mevaluate(x_batch, y_batch, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     98\u001b[0m     \u001b[39m# Update total loss and accuracy\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss \u001b[39m*\u001b[39m x_batch\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "loss, accuracy = model1.evaluate (test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcv-gt24-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
